Here are two files i have that i need working properly in my model. 

1. = __feature_helpers.py ( see below )

import pandas as pd 
from _team_stat_helpers import get_team_stats_df

def enrich_with_adv_player_stats(past_games):
    """
    Enriches the given past_games DataFrame with advanced player-level stats
    like USG_PCT, POSS, E_PACE from the merged CSV (loaded via team_stat_helpers).
    Merges on PLAYER_ID and GAME_DATE.
    """
    adv_df = get_team_stats_df()
    if adv_df is None:
        raise RuntimeError("Advanced stats not loaded. Call load_team_stats() first.")

    # Strip column names
    adv_df.columns = adv_df.columns.str.strip()
    past_games.columns = past_games.columns.str.strip()

    # Columns to pull in
    adv_columns = [
        'PLAYER_ID', 'GAME_DATE', 
        'AST_PCT', 'OREB_PCT', 'REB_PCT', 'DREB_PCT', 
        'E_PACE', 'POSS']

    # Inner join on PLAYER_ID and GAME_DATE
    enriched = pd.merge(
        past_games,
        adv_df[adv_columns],
        on=['PLAYER_ID', 'GAME_DATE'],
        how='left',
        suffixes=('', '_ADV')
    )

    return enriched

def enrich_current_game_with_adv_stats(current_game):
    """
    Enriches a single game row with advanced stats from the merged CSV.
    Expects current_game to be a Series with PLAYER_ID and GAME_DATE.
    """
    adv_df = get_team_stats_df()
    if adv_df is None:
        raise RuntimeError("Advanced stats not loaded. Call load_team_stats() first.")

    adv_df.columns = adv_df.columns.str.strip()
    player_id = current_game['PLAYER_ID']
    game_date = pd.to_datetime(current_game['GAME_DATE'])

    # Filter down to matching player + game
    match = adv_df[
        (adv_df['PLAYER_ID'] == player_id) &
        (adv_df['GAME_DATE'] == game_date)
    ]
    print(match.head())
    if match.empty:
        print(f"[!] No advanced stats found for PLAYER_ID {player_id} on {game_date.date()}")
        return current_game  # Return original, unmodified

    # Add each matching stat to the row
    for stat in ['AST_PCT', 'OREB_PCT', 'REB_PCT', 'DREB_PCT', 'E_PACE', 'POSS', 'TEAM_BLK', 'TEAM_STL', 'TEAM_PF']:
        if stat in match.columns:
            current_game[stat] = match[stat].values[0]

    return current_game


THE OTHER FILE I HAVE IS: 
-team_stat_helpers.py ( see below )

import pandas as pd
import numpy as np

_team_stats_df = None  # Global variable

def load_team_stats(filepath='merged_player_team_adv_stats_2024-25.csv'):
    global _team_stats_df
    _team_stats_df = pd.read_csv(filepath, parse_dates=['GAME_DATE'])
    _team_stats_df.columns = _team_stats_df.columns.str.strip()  # Normalize
    print(f"[âœ“] Loaded team stats with {len(_team_stats_df)} rows.")

def get_team_rolling_avg(team_id, current_game_date, stat_col, window=5):
    if _team_stats_df is None:
        raise RuntimeError("Team stats not loaded. Call load_team_stats() first.")

    df = _team_stats_df.copy()
    df = df[df['TEAM_ID'] == team_id]
    df = df[df['GAME_DATE'] < pd.to_datetime(current_game_date)]
    df = df.sort_values('GAME_DATE')

    if stat_col not in df.columns or df.empty:
        return np.nan

    return df[stat_col].tail(window).mean()

def get_latest_team_stat(team_id, current_game_date, stat_col):
    if _team_stats_df is None:
        raise RuntimeError("Team stats not loaded. Call load_team_stats() first.")

    df = _team_stats_df.copy()
    df = df[df['TEAM_ID'] == team_id]
    df = df[df['GAME_DATE'] < pd.to_datetime(current_game_date)]
    df = df.sort_values('GAME_DATE')

    if stat_col not in df.columns or df.empty:
        return np.nan

    return df.iloc[-1][stat_col]


def get_def_vs_avg_scale(opp_team_id, game_date, stat_col='TEAM_DEF_RATING'):
    """
    This is for opponent defense adjustment based on how much they hold players below their season average.
    Returns scale factor: league_avg_stat / opponent_recent_stat
    Example: If opp_def_rating is low, this will return a multiplier < 1
    """
    if _team_stats_df is None:
        raise RuntimeError("Team stats not loaded. Call load_team_stats() first.")

    df = _team_stats_df.copy()
    df = df[df['TEAM_ID'] == opp_team_id]
    df = df[df['GAME_DATE'] < pd.to_datetime(game_date)]
    df = df.sort_values('GAME_DATE')

    if stat_col not in df.columns or len(df) < 5:
        return 1.0  # Default scaling

    # Compare most recent value to 5-game average before it
    last_val = df[stat_col].iloc[-1]
    rolling_avg = df[stat_col].iloc[-6:-1].mean()

    if np.isnan(last_val) or np.isnan(rolling_avg) or rolling_avg == 0:
        return 1.0

    return last_val / rolling_avg

def get_team_stats_df():
    global _team_stats_df
    return _team_stats_df

load_team_stats("merged_player_team_adv_stats_2024-25.csv")


HOW DO I GET THESE WORKING TOGETHER PROPERLY SO THAT MY CORRECT COLUMN NAMES WITH DATA GO THROUGH TO THE FINAL 'merged_df' inside of TnP_merger.py 

Here is team_adv_tracker.py that gathers all of the data.. for reference. 

import pandas as pd
import time
from nba_api.stats.endpoints import leaguegamefinder, boxscoreadvancedv2, boxscoretraditionalv2
from nba_api.stats.library.parameters import SeasonAll

"""
    This script uses NBA_API to gathers team data which cannot be located through any log like: 
    'OFF_RATING', 'DEF_RATING', 'E_OFF_RATING', 'E_DEF_RATING', 'AST_PCT', 'REB_PCT']
    and creates a dataframe with those variables recorded for each game.
    
    This code still needs further development to do the same for player data like USG_PCT. 
"""

def get_all_game_ids(season ='2024-25'):
    print("[*] Fetching all game IDs...")
    gf = leaguegamefinder.LeagueGameFinder(season_nullable=season)
    games = gf.get_data_frames()[0]
    games = games[['GAME_ID', 'GAME_DATE']]
    games.drop_duplicates(subset='GAME_ID', inplace=True)
    games['GAME_DATE'] = pd.to_datetime(games['GAME_DATE'])
    return games

def build_team_adv_dataset(season='2024-25', chunk_index=0, num_chunks=4, save_csv=True):
    games_df = get_all_game_ids(season)
    games_df.sort_values('GAME_DATE', inplace=True)
    
    # Split into chunks
    chunk_size = len(games_df) // num_chunks
    start_idx = chunk_index * chunk_size
    end_idx = len(games_df) if chunk_index == num_chunks - 1 else (chunk_index + 1) * chunk_size
    chunk_df = games_df.iloc[start_idx:end_idx].reset_index(drop=True)

    print(f" Processing chunk {chunk_index + 1}/{num_chunks}: {len(chunk_df)} games")

    all_rows = []

    for i, row in chunk_df.iterrows():
        game_id = row['GAME_ID']
        game_date = row['GAME_DATE']

        try:
            print(f"[{i+1}/{len(chunk_df)}] Processing {game_id}")
            box = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id)
            team_stats = box.get_data_frames()[1]  # TeamStats
            team_stats['GAME_ID'] = game_id
            team_stats['GAME_DATE'] = game_date

            slim = team_stats[[
                'TEAM_ID', 'TEAM_NAME', 'GAME_ID', 'GAME_DATE',
                'OFF_RATING', 'DEF_RATING', 'E_OFF_RATING', 'E_DEF_RATING',
                'AST_PCT', 'REB_PCT', 'PACE', 'E_PACE'
            ]]

            box = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=game_id)
            team_traditional = box.get_data_frames()[1]  # Team stats

            team_traditional = team_traditional[['TEAM_ID', 'BLK', 'STL', 'PF']]
            team_traditional.columns = ['TEAM_ID', 'TEAM_BLK', 'TEAM_STL', 'TEAM_PF']

            team_stats = pd.merge(team_stats, team_traditional, on='TEAM_ID', how='left')


            all_rows.append(slim)
            time.sleep(1.0)

        except Exception as e:
            print(f"[!] Error fetching {game_id}: {e}")
            continue


    full_df = pd.concat(all_rows, ignore_index=True)

    if save_csv:
        out_file = f'team_advanced_stats_chunk_{chunk_index + 1}.csv'
        full_df.to_csv(out_file, index=False)
        print(f" Chunk saved to {out_file}")

    return full_df

if __name__ == '__main__':
    
    """Change the 'chunk_index=__' after running each set. Start with 0, then 1, then 2, then 3"""
    
    # Step 1: Run chunk 1
    chunk_df = build_team_adv_dataset(season='2024-25', chunk_index=0, save_csv=True)
    # Preview the output
    print(chunk_df.head())

