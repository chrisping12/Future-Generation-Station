Absolutely — plotting decision boundaries can really help you visualize how different feature combinations separate classes. Here’s a full drop-in loop that will:
	•	Take your dataset and labels.
	•	Use a classifier (default: LogisticRegression or change to another like RandomForestClassifier).
	•	Loop over all 2D combinations of the top 5 features.
	•	Fit the classifier and plot decision boundaries.
	•	Save each plot to a folder.

⸻

Full Code: plot_decision_boundaries.py

import os
import itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression  # Or use any other classifier
from sklearn.model_selection import train_test_split
from sklearn.inspection import DecisionBoundaryDisplay

def plot_decision_boundaries(df, labels, top_features, model=None, output_dir='decision_boundaries'):
    """
    Plots decision boundaries for every pair of top features and saves the plots.

    Parameters:
        df (pd.DataFrame): Feature DataFrame.
        labels (pd.Series or array-like): Target labels.
        top_features (list): Top 5 feature names to use for combinations.
        model: Scikit-learn classifier. Default is LogisticRegression.
        output_dir (str): Directory to save plots.
    """

    if model is None:
        model = LogisticRegression()

    os.makedirs(output_dir, exist_ok=True)

    # Loop through all 2D combinations of the top features
    combos = list(itertools.combinations(top_features, 2))
    for i, (feat1, feat2) in enumerate(combos):
        print(f"[{i+1}/{len(combos)}] Plotting decision boundary for: {feat1} vs {feat2}")

        X = df[[feat1, feat2]].copy()
        y = np.array(labels)

        # Scale features for better boundary plotting
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Train model
        model.fit(X_scaled, y)

        # Plot
        disp = DecisionBoundaryDisplay.from_estimator(
            model,
            X_scaled,
            response_method="predict",
            alpha=0.5,
            xlabel=feat1,
            ylabel=feat2
        )

        # Plot points
        scatter = disp.ax_.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, edgecolor='k', cmap='coolwarm', s=20)
        disp.ax_.set_title(f"{feat1} vs {feat2}")
        
        # Save
        file_path = os.path.join(output_dir, f"boundary_{feat1}_vs_{feat2}.png")
        plt.savefig(file_path)
        plt.close()

    print(f"\nAll decision boundaries saved to: {output_dir}")

# Example usage:
# Assuming you already have `features_df` and `labels` defined:
# top_features = ['PTS', 'USG_PCT', 'REB_5G', 'AST_5G', 'FG3A']
# plot_decision_boundaries(features_df, labels, top_features)



⸻

What You Need to Plug In
	•	features_df: Your cleaned and scaled feature DataFrame.
	•	labels: Your classification targets (e.g., 1 if they hit 20+ points, else 0).
	•	top_features: A list of the 5 feature names you want to visualize boundaries for.

⸻

Let me know if you’d like:
	•	A 3D decision surface for 3-feature combinations,
	•	To run this on only a specific player’s data,
	•	Or if you’re using PySR and want to plot decision surfaces from symbolic formulas instead.